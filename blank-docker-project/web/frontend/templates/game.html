<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>

    <!--library for make request HTTP-->
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>

    <script>
        const getRequest = async () => {
            const response = await axios.get('/frontend/sendframe', {
                params: {
                    "test": "this is a test",
                }
            },
            )
            console.log(response.data)

        }
        getRequest();
    </script>

    <!-- Load TensorFlow.js -->
    <script src="https://unpkg.com/@tensorflow/tfjs"></script>

    <!-- Load Posenet -->
    <script src="https://unpkg.com/@tensorflow-models/posenet"></script>
    <script type="text/javascript" src="https://unpkg.com/webcam-easy/dist/webcam-easy.min.js"></script>
    <script type="module" src="{% static 'utils.js' %}"></script>

    <h1>Game</h1>
    <img src="{% static 'assets/logo.png' %}">
    <div id="Container">
        <video autoplay="true" id="videoElement" width="640" height="480"></video>
        <canvas id="myCanvas" width="640" height="480"></canvas>
    </div>

    <script type="module">
        import { drawKeypoints, drawSkeleton } from "{% static 'utils.js' %}"

        const webcamElement = document.getElementById('videoElement');
        const canvasElement = document.getElementById('myCanvas');
        const webcam = new Webcam(webcamElement, 'user', canvasElement);
        webcam.start();

        const ctx = canvasElement.getContext("2d");
        ctx.translate(canvasElement.width, 0);
        ctx.scale(-1, 1);

        async function loadVideo() {
            return webcamElement;
        }

        const runPosenet = async () => {
            const net = await posenet.load({
                inputResolution: { width: 640, height: 480 },
                scale: 0.5
            })
            setInterval(() => {
                detect(net)
            }, 1000);
        }

        const detect = async (net) => {

            if (loadVideo() != null) {

                const video = await loadVideo();
                const pose = await net.estimateSinglePose(video); //important: estimateSinglePose take on input only dom element. video is a reference to video tag inside dom tree
                drawCanvas(pose, video, canvasElement);

                midle_point()

            }
        }

        const drawCanvas = (pose, video, canvas) => { //pose["keypoints"] contains an array of objects with detected body points and coordinates inside
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            drawKeypoints(pose["keypoints"], 0.5, ctx);
            drawSkeleton(pose["keypoints"], 0.5, ctx);
        }

        function midle_point() {
            var p= require("{%static 'bacco.json'%}")
            json=p
            var x = 0, y = 0, count = 0
            json["keypoints"].forEach(element => {
                if (element["score"] > 0, 3) {
                    x += element["position"]["x"]
                    y += element["position"]["y"]
                    count++
                }

            })
            x = x / count
            y = y / count
            console.log(x)
            console.log(y)
        }

        runPosenet();
    </script>
</body>
</html>